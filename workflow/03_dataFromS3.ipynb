{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==1.7.3 in /opt/conda/lib/python3.7/site-packages (1.7.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-nlp==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_242\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)\n",
      "OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)\n",
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!java -version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType, StructType, StructField, FloatType, IntegerType, LongType, StringType, DataType\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf,col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from datetime import datetime\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_parquet(parquet_path):\n",
    "    ! ls 2>&1 -lh $parquet_path | head -10\n",
    "    ! echo 'Parquet Files:' $(ls | wc -l)\n",
    "    table_parquet = spark.read.parquet(parquet_path)\n",
    "    print('DataFrame rows: %d' % table_parquet.count())\n",
    "    print('DataFrame schema: %s' % table_parquet)\n",
    "    table_parquet.show(10, False)\n",
    "    return table_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_timestamp(df):\n",
    "    # convert timestamps to date time from epoch time so we can get hour of the day\n",
    "    get_timestamp = F.udf(lambda x: datetime.fromtimestamp(x/1000), T.TimestampType())\n",
    "    # add a new column `formated_ts` in our dataframe\n",
    "    df_log_copy = df.withColumn(\"timestamp\", get_timestamp(df.ts))\n",
    "    # remove rows with empty ts value\n",
    "    df_formated = df_log_copy.dropna(subset='timestamp')\n",
    "    return df_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parquet_song(table, parquet_path):\n",
    "    table.write.partitionBy(\"year\", \"artist_id\").parquet(parquet_path, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parquet(table, parquet_path):\n",
    "    table.write.parquet(parquet_path, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parquet_time(table, parquet_path):\n",
    "    table.write.partitionBy(['year', 'month']).parquet(parquet_path, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET AWS KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credentials():\n",
    "    \"\"\"\n",
    "    get AWS keys\n",
    "    \"\"\"\n",
    "    # parse file\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dl.cfg')\n",
    "    # set AWS variables\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = config['AWS']['KEY']\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['SECRET']\n",
    "    \n",
    "get_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIATE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6ad842382293:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd26ecdf050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "        Create or load a Spark session\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"s3a://udacity-dend/\"\n",
    "output_data = \"./output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS SONG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "song_files = \"song_data/A/A/A/*.json\"\n",
    "#input_song = input_data + song_files\n",
    "input_song = \"s3a://udacity-dend/song_data/A/A/A/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song_data(spark, input_data):\n",
    "    '''\n",
    "    process song data\n",
    "    \n",
    "    return df_song\n",
    "    '''\n",
    "    # read  data file\n",
    "    song_schema = StructType([\n",
    "        StructField(\"num_songs\", IntegerType()),\n",
    "        StructField(\"artist_id\", StringType()),\n",
    "        StructField(\"artist_latitude\", FloatType()),\n",
    "        StructField(\"artist_longitude\", FloatType()),\n",
    "        StructField(\"artist_location\", StringType()),\n",
    "        StructField(\"artist_name\", StringType()),\n",
    "        StructField(\"song_id\", StringType()),\n",
    "        StructField(\"title\", StringType()),\n",
    "        StructField(\"duration\", FloatType()),\n",
    "        StructField(\"year\", IntegerType())\n",
    "    ])    \n",
    "    df_song = spark.read.json(input_song, schema = song_schema)\n",
    "    # print('DataFrame rows: %d' % df_song.count())\n",
    "    df_song.printSchema()\n",
    "    print('DataFrame schema: %s' % df_song)\n",
    "    return df_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: float (nullable = true)\n",
      " |-- artist_longitude: float (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: float (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "DataFrame schema: DataFrame[num_songs: int, artist_id: string, artist_latitude: float, artist_longitude: float, artist_location: string, artist_name: string, song_id: string, title: string, duration: float, year: int]\n"
     ]
    }
   ],
   "source": [
    "df_song = process_song_data(spark, input_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create songs Table\n",
    "\n",
    "* varchar : song_id, title, artist_id\n",
    "* float : user_id\n",
    "* int: year\n",
    "* NOT NULL : song_id, title, artist_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_songs_table(df):\n",
    "    table = df_song \\\n",
    "        .drop_duplicates(['song_id']) \\\n",
    "        .select(\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\") \\\n",
    "        .filter('song_id != \"\" and title != \"\" and artist_id != \"\"') \\\n",
    "        .sort(\"song_id\") \n",
    "    return(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOABWAP12A8C13F82A|           Take Time|AR5LMPY1187FB573FE|1978|258.89914|\n",
      "|SOAFBCP12A8C13CC7D|King Of Scurf (20...|ARTC1LV1187B9A4858|1972|301.40036|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process and check\n",
    "songs_table = create_songs_table(df_song)\n",
    "songs_table.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_table.collect()\n",
    "parquet_path = output_data + 'songs_table'\n",
    "write_parquet_song(songs_table, parquet_path)\n",
    "# check_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Artists Table\n",
    "\n",
    "* varchar : artist_id, name, location\n",
    "* float : latitude, longitude\n",
    "* NOT NULL : artist_id, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artists_table(df):\n",
    "    table = df \\\n",
    "        .drop_duplicates(['artist_id']) \\\n",
    "        .selectExpr(\"artist_id\", \"artist_name as name\", \"artist_location as location\", \"artist_latitude as latitude\", \"artist_longitude as longitude\") \\\n",
    "        .filter('artist_id != \"\" and name != \"\"') \\\n",
    "        .sort(\"artist_id\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|         artist_id|                name|            location|latitude|longitude|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|AR0MWD61187B9B2B12|International Noi...|                    |    null|     null|\n",
      "|AR10USD1187B99F3F1|Tweeterfriendly M...|Burlington, Ontar...|    null|     null|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process and check\n",
    "artists_table = create_artists_table(df_song)\n",
    "artists_table.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_table.collect()\n",
    "parquet_path = output_data + '/artists_table'\n",
    "write_parquet(artists_table, parquet_path)\n",
    "# check_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output//artists_table\n"
     ]
    }
   ],
   "source": [
    "print(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://udacity-dend/log_data/*/*/*.json\n"
     ]
    }
   ],
   "source": [
    "input_log = \"s3a://udacity-dend/log_data/*/*/*.json\"\n",
    "print(input_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"s3a://udacity-dend/\"\n",
    "#log_data = \"log_data/*/*/*.json\"\n",
    "#input_log = input_data + log_data\n",
    "input_log = \"s3a://udacity-dend/log_data/*/*/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_data(spark, input_log):\n",
    "    '''\n",
    "    process log data\n",
    "    \n",
    "    return df_log\n",
    "    '''\n",
    "    # read log data file\n",
    "    log_schema = StructType([\n",
    "        StructField(\"artist\", StringType()),\n",
    "        StructField(\"auth\", StringType()),\n",
    "        StructField(\"firstName\", StringType()),\n",
    "        StructField(\"gender\", StringType()),\n",
    "        StructField(\"itemInSession\", IntegerType()),\n",
    "        StructField(\"lastName\", StringType()),\n",
    "        StructField(\"length\", FloatType()),    \n",
    "        StructField(\"level\", StringType()),\n",
    "        StructField(\"location\", StringType()),\n",
    "        StructField(\"method\", StringType()),\n",
    "        StructField(\"page\", StringType()),\n",
    "        StructField(\"registration\", FloatType()),\n",
    "        StructField(\"sessionId\", StringType()),\n",
    "        StructField(\"song\", StringType()),\n",
    "        StructField(\"status\", IntegerType()),\n",
    "        StructField(\"ts\", LongType()),\n",
    "        StructField(\"userAgent\", StringType()),\n",
    "        StructField(\"userId\", StringType())\n",
    "    ])\n",
    "    \n",
    "    df_log_raw = spark.read.json(input_log, schema = log_schema)\n",
    "    print('DataFrame raw: %d' % df_log_raw.count())\n",
    "    df_log = df_log_raw.filter(\"page='NextSong'\")\n",
    "    print('DataFrame next: %d' % df_log.count())\n",
    "    df_ts=clean_timestamp(df_log)    \n",
    "    # print('DataFrame rows: %d' % df_log.count())\n",
    "    df_ts.printSchema()\n",
    "    print('DataFrame schema: %s' % df_log)\n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame raw: 8056\n",
      "DataFrame next: 6820\n",
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: integer (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: float (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: float (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: integer (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "DataFrame schema: DataFrame[artist: string, auth: string, firstName: string, gender: string, itemInSession: int, lastName: string, length: float, level: string, location: string, method: string, page: string, registration: float, sessionId: string, song: string, status: int, ts: bigint, userAgent: string, userId: string]\n"
     ]
    }
   ],
   "source": [
    "df_log= process_log_data(spark, input_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create users table\n",
    "\n",
    "* bigint: user_Id\n",
    "* varchar first_name, last_name, gender\n",
    "* NOT NULL : user_id, level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_users_table(df):\n",
    "    users_table = df \\\n",
    "        .drop_duplicates(subset = ['userId']) \\\n",
    "        .filter('level != \"\"' and 'userId != \"\"') \\\n",
    "        .orderBy(\"ts\", ascending = False) \\\n",
    "        .coalesce(1)\\\n",
    "        .selectExpr(\"cast(userId as Long) user_id\", \"firstName as first_name\", \"lastName as last_name\", \"gender\", \"level\")   \\\n",
    "        .sort('user_id')\n",
    "    return users_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|      2|   Jizelle| Benjamin|     F| free|\n",
      "|      3|     Isaac|   Valdez|     M| free|\n",
      "|      4|    Alivia|  Terrell|     F| free|\n",
      "|      5|    Elijah|    Davis|     M| free|\n",
      "|      6|   Cecilia|    Owens|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process and check\n",
    "users_table = create_users_table(df_log)\n",
    "users_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table.collect()\n",
    "parquet_path = 'output/users_table'\n",
    "write_parquet(users_table, parquet_path)\n",
    "# check_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time table\n",
    "\n",
    "* timestamp: start_time\n",
    "* int: hour, day, week, month, year\n",
    "* varchar:  weekday\n",
    "* NOT NULL : start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_table(df):\n",
    "    time_df = df \\\n",
    "        .drop_duplicates(['timestamp']) \\\n",
    "        .select( \\\n",
    "            col('timestamp').alias(\"start_time\"),\n",
    "            hour(col('timestamp')).alias('hour'),\n",
    "            dayofmonth(col('timestamp')).alias('day'),\n",
    "            weekofyear(col('timestamp')).alias('week'),\n",
    "            month(col('timestamp')).alias('month'),\n",
    "            year(col('timestamp')).alias('year')) \\\n",
    "        .sort('start_time')\n",
    "\n",
    "    time_table = time_df.withColumn('hour', F.hour('start_time')) \\\n",
    "                    .withColumn('day', F.dayofmonth('start_time')) \\\n",
    "                    .withColumn('year', F.year('start_time')) \\\n",
    "                    .withColumn('week', F.weekofyear('start_time')) \\\n",
    "                    .withColumn('month', F.month('start_time')) \\\n",
    "                    .withColumn('weekday', F.dayofweek('start_time').cast(\"string\"))\n",
    "    return time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-01 21:01:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:05:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:08:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:11:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:17:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:24:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:28:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:42:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:52:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 21:55:...|  21|  1|  44|   11|2018|      5|\n",
      "|2018-11-01 22:23:...|  22|  1|  44|   11|2018|      5|\n",
      "|2018-11-02 01:25:...|   1|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 01:30:...|   1|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 01:34:...|   1|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 02:42:...|   2|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 03:05:...|   3|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 03:34:...|   3|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 05:15:...|   5|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 05:52:...|   5|  2|  44|   11|2018|      6|\n",
      "|2018-11-02 09:01:...|   9|  2|  44|   11|2018|      6|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process and check\n",
    "time_table = create_time_table(df_log)\n",
    "time_table.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table.collect()\n",
    "parquet_path = 'output/time_table'\n",
    "write_parquet_time(time_table, parquet_path)\n",
    "# check_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the songplays fact table\n",
    "\n",
    "* bigint: songplay_id, user_id\n",
    "* timestamp : start_time\n",
    "* varchar : level, song_id, artist_id, session_id, location, user_agent\n",
    "* int: month, year\n",
    "* NOT NULL : start_time, user_id, level, session_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_songplays_table(df, ts):\n",
    "    tl = df_log.alias('tl')\n",
    "    ts = df_song.alias('ts')\n",
    "    \n",
    "    inner_join = tl.join(ts, ((tl.artist == ts.artist_name) & (tl.artist == ts.artist_name)), how='inner')\n",
    "    \n",
    "    songplays = inner_join \\\n",
    "            .withColumn(\"songplay_id\", monotonically_increasing_id()) \\\n",
    "            .filter('timestamp != \"\"' and 'userId != \"\"' and 'level != \"\"' and 'sessionId != \"\"')\n",
    "    \n",
    "    songplays_table = songplays \\\n",
    "                    .selectExpr(\"songplay_id\",\n",
    "                                    \"timestamp as start_time\",\n",
    "                                    \"cast(userId as Long) user_id\",\n",
    "                                    \"level\",\n",
    "                                    \"song_id\",\n",
    "                                    \"artist_id\",\n",
    "                                    \"sessionId as session_id\",\n",
    "                                    \"location\",\n",
    "                                    \"userAgent as user_agent\") \\\n",
    "                    .sort('songplay_id') \\\n",
    "                    .withColumn('year', F.year('start_time')) \\\n",
    "                    .withColumn('month', F.month('start_time'))\n",
    "\n",
    "    return songplays_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          0|2018-11-15 16:55:...|     42| paid|SONRWUU12AF72A4283|ARGE7G11187FB37E05|       404|New York-Newark-J...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "|          1|2018-11-21 05:30:...|     97| paid|SONRWUU12AF72A4283|ARGE7G11187FB37E05|       797|Lansing-East Lans...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|          2|2018-11-28 16:54:...|     14| free|SOIGHOD12A8C13B5A1|ARY589G1187B9A9F4E|       929|       Red Bluff, CA|Mozilla/5.0 (Wind...|2018|   11|\n",
      "|          3|2018-11-05 02:21:...|     44| paid|SONRWUU12AF72A4283|ARGE7G11187FB37E05|       237|Waterloo-Cedar Fa...|Mozilla/5.0 (Maci...|2018|   11|\n",
      "|          4|2018-11-30 13:20:...|     43| free|SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|       618|San Antonio-New B...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process and check\n",
    "songplays_table = create_songplays_table(df_log, df_song)\n",
    "songplays_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process and check\n",
    "songplays_table = create_songplays_table(df_log, df_song)\n",
    "parquet_path = 'output/songplays_table'\n",
    "write_parquet_time(songplays_table, parquet_path)\n",
    "# check_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|song_id           |count|\n",
      "+------------------+-----+\n",
      "|SOABWAP12A8C13F82A|1    |\n",
      "|SOAFBCP12A8C13CC7D|1    |\n",
      "+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "Not Null with filter: 24 \n",
      "Null with filter: 0 \n",
      "+--------------------------------+-----+\n",
      "|title                           |count|\n",
      "+--------------------------------+-----+\n",
      "|A Poor Recipe For Civic Cohesion|1    |\n",
      "|Burn My Body (Album Version)    |1    |\n",
      "+--------------------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "Not Null with filter: 24 \n",
      "Null with filter: 0 \n",
      "+------------------+-----+\n",
      "|artist_id         |count|\n",
      "+------------------+-----+\n",
      "|AR0MWD61187B9B2B12|1    |\n",
      "|AR10USD1187B99F3F1|1    |\n",
      "+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "Not Null with filter: 24 \n",
      "Null with filter: 0 \n",
      "Numbers of rows in songs_table : 24\n",
      "Not Null song_id with filter: 24 \n",
      "Null with song_id filter: 0 \n",
      "Not Null title with filter: 24 \n",
      "Null with title filter: 0 \n",
      "Not Null artist_id with filter: 24 \n",
      "Null with artist_id filter: 0 \n",
      "total 4.0K\n",
      "-rw-r--r-- 1 anthelix users    0 Mar 27 14:04 _SUCCESS\n",
      "drwxr-xr-x 3 anthelix users 4.0K Mar 27 14:04 year=2018\n",
      "Parquet Files: 16\n",
      "DataFrame rows: 10\n",
      "DataFrame schema: DataFrame[songplay_id: bigint, start_time: timestamp, user_id: bigint, level: string, song_id: string, artist_id: string, session_id: string, location: string, user_agent: string, year: int, month: int]\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|songplay_id|start_time             |user_id|level|song_id           |artist_id         |session_id|location                             |user_agent                                                                                                     |year|month|\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|0          |2018-11-15 16:55:31.796|42     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|404       |New York-Newark-Jersey City, NY-NJ-PA|\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|4          |2018-11-30 13:20:44.796|43     |free |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|618       |San Antonio-New Braunfels, TX        |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|5          |2018-11-16 16:40:43.796|97     |paid |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|633       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|1          |2018-11-21 05:30:19.796|97     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|797       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|17179869184|2018-11-06 20:05:45.796|97     |paid |SOBLFFE12AF72AA5BA|ARJNIUY12298900C91|293       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|8589934592 |2018-11-20 00:51:41.796|25     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|594       |Marinette, WI-MI                     |\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|8589934594 |2018-11-27 17:08:42.796|36     |paid |SORRNOC12AB017F52B|ARSZ7L31187FB4E610|957       |Janesville-Beloit, WI                |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|3          |2018-11-05 02:21:55.796|44     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|237       |Waterloo-Cedar Falls, IA             |Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0                              |2018|11   |\n",
      "|8589934593 |2018-11-19 15:36:04.796|49     |paid |SOFSOCN12A8C143F5D|ARXR32B1187FB57099|724       |San Francisco-Oakland-Hayward, CA    |Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0                                              |2018|11   |\n",
      "|2          |2018-11-28 16:54:51.796|14     |free |SOIGHOD12A8C13B5A1|ARY589G1187B9A9F4E|929       |Red Bluff, CA                        |Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0                                       |2018|11   |\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "\n",
      "+------------------+-----+\n",
      "|artist_id         |count|\n",
      "+------------------+-----+\n",
      "|AR0MWD61187B9B2B12|1    |\n",
      "|AR10USD1187B99F3F1|1    |\n",
      "+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "Not Null artist_id with filter: 24 \n",
      "Null artist_id with filter: 0 \n",
      "+---------------+-----+\n",
      "|artist_name    |count|\n",
      "+---------------+-----+\n",
      "|Adelitas Way   |1    |\n",
      "|Broken Spindles|1    |\n",
      "+---------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "Not Null artist_name with filter: 24 \n",
      "Null artist_name with filter: 0 \n",
      "Numbers of rows in artists_table : 24\n",
      "Not Null artist_id  with filter: 24 \n",
      "Null with artist_id  filter: 0 \n",
      "Not Null name with filter: 24 \n",
      "Null with name filter: 0 \n",
      "total 4.0K\n",
      "-rw-r--r-- 1 anthelix users    0 Mar 27 14:04 _SUCCESS\n",
      "drwxr-xr-x 3 anthelix users 4.0K Mar 27 14:04 year=2018\n",
      "Parquet Files: 16\n",
      "DataFrame rows: 10\n",
      "DataFrame schema: DataFrame[songplay_id: bigint, start_time: timestamp, user_id: bigint, level: string, song_id: string, artist_id: string, session_id: string, location: string, user_agent: string, year: int, month: int]\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|songplay_id|start_time             |user_id|level|song_id           |artist_id         |session_id|location                             |user_agent                                                                                                     |year|month|\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|0          |2018-11-15 16:55:31.796|42     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|404       |New York-Newark-Jersey City, NY-NJ-PA|\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|4          |2018-11-30 13:20:44.796|43     |free |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|618       |San Antonio-New Braunfels, TX        |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|5          |2018-11-16 16:40:43.796|97     |paid |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|633       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|1          |2018-11-21 05:30:19.796|97     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|797       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|17179869184|2018-11-06 20:05:45.796|97     |paid |SOBLFFE12AF72AA5BA|ARJNIUY12298900C91|293       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|8589934592 |2018-11-20 00:51:41.796|25     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|594       |Marinette, WI-MI                     |\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|8589934594 |2018-11-27 17:08:42.796|36     |paid |SORRNOC12AB017F52B|ARSZ7L31187FB4E610|957       |Janesville-Beloit, WI                |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|3          |2018-11-05 02:21:55.796|44     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|237       |Waterloo-Cedar Falls, IA             |Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0                              |2018|11   |\n",
      "|8589934593 |2018-11-19 15:36:04.796|49     |paid |SOFSOCN12A8C143F5D|ARXR32B1187FB57099|724       |San Francisco-Oakland-Hayward, CA    |Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0                                              |2018|11   |\n",
      "|2          |2018-11-28 16:54:51.796|14     |free |SOIGHOD12A8C13B5A1|ARY589G1187B9A9F4E|929       |Red Bluff, CA                        |Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0                                       |2018|11   |\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|49    |689  |\n",
      "|80    |665  |\n",
      "|97    |557  |\n",
      "|15    |463  |\n",
      "|44    |397  |\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Not Null userId with filter: 6820 \n",
      "Null userId with filter: 0 \n",
      "+-----+-----+\n",
      "|level|count|\n",
      "+-----+-----+\n",
      "|paid |5591 |\n",
      "|free |1229 |\n",
      "+-----+-----+\n",
      "\n",
      "Not Null level with filter: 6820 \n",
      "Null level with filter: 0 \n",
      "Numbers of rows in users_table : 96\n",
      "Not Null user_idwith filter: 96 \n",
      "Null with user_id filter: 0 \n",
      "total 4.0K\n",
      "-rw-r--r-- 1 anthelix users    0 Mar 27 14:04 _SUCCESS\n",
      "drwxr-xr-x 3 anthelix users 4.0K Mar 27 14:04 year=2018\n",
      "Parquet Files: 16\n",
      "DataFrame rows: 10\n",
      "DataFrame schema: DataFrame[songplay_id: bigint, start_time: timestamp, user_id: bigint, level: string, song_id: string, artist_id: string, session_id: string, location: string, user_agent: string, year: int, month: int]\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|songplay_id|start_time             |user_id|level|song_id           |artist_id         |session_id|location                             |user_agent                                                                                                     |year|month|\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|0          |2018-11-15 16:55:31.796|42     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|404       |New York-Newark-Jersey City, NY-NJ-PA|\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|4          |2018-11-30 13:20:44.796|43     |free |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|618       |San Antonio-New Braunfels, TX        |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|5          |2018-11-16 16:40:43.796|97     |paid |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|633       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|1          |2018-11-21 05:30:19.796|97     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|797       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|17179869184|2018-11-06 20:05:45.796|97     |paid |SOBLFFE12AF72AA5BA|ARJNIUY12298900C91|293       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|8589934592 |2018-11-20 00:51:41.796|25     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|594       |Marinette, WI-MI                     |\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|8589934594 |2018-11-27 17:08:42.796|36     |paid |SORRNOC12AB017F52B|ARSZ7L31187FB4E610|957       |Janesville-Beloit, WI                |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|3          |2018-11-05 02:21:55.796|44     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|237       |Waterloo-Cedar Falls, IA             |Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0                              |2018|11   |\n",
      "|8589934593 |2018-11-19 15:36:04.796|49     |paid |SOFSOCN12A8C143F5D|ARXR32B1187FB57099|724       |San Francisco-Oakland-Hayward, CA    |Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0                                              |2018|11   |\n",
      "|2          |2018-11-28 16:54:51.796|14     |free |SOIGHOD12A8C13B5A1|ARY589G1187B9A9F4E|929       |Red Bluff, CA                        |Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0                                       |2018|11   |\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "\n",
      "+-----------------------+-----+\n",
      "|timestamp              |count|\n",
      "+-----------------------+-----+\n",
      "|2018-11-14 04:53:36.796|2    |\n",
      "|2018-11-15 18:55:04.796|2    |\n",
      "|2018-11-23 14:41:51.796|2    |\n",
      "|2018-11-24 14:29:47.796|2    |\n",
      "|2018-11-27 17:28:50.796|2    |\n",
      "+-----------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Not Null formated_ts with filter: 6820 \n",
      "Null with formated_ts filter: 0 \n",
      "Numbers of rows in users_table : 6813\n",
      "Not Null with filter: 6813 \n",
      "Null with filter: 0 \n",
      "Numbers of rows in songplays_table : 10\n",
      "Not Null start_time with filter: 10 \n",
      "Null start_time with filter: 0 \n",
      "Not Null user_id with filter: 10 \n",
      "Null user_id with filter: 0 \n",
      "Not Null level with filter: 10 \n",
      "Null level with filter: 0 \n",
      "Not Null session_id with filter: 10 \n",
      "Null session_id with filter: 0 \n",
      "total 4.0K\n",
      "-rw-r--r-- 1 anthelix users    0 Mar 27 14:04 _SUCCESS\n",
      "drwxr-xr-x 3 anthelix users 4.0K Mar 27 14:04 year=2018\n",
      "Parquet Files: 16\n",
      "DataFrame rows: 10\n",
      "DataFrame schema: DataFrame[songplay_id: bigint, start_time: timestamp, user_id: bigint, level: string, song_id: string, artist_id: string, session_id: string, location: string, user_agent: string, year: int, month: int]\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|songplay_id|start_time             |user_id|level|song_id           |artist_id         |session_id|location                             |user_agent                                                                                                     |year|month|\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "|0          |2018-11-15 16:55:31.796|42     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|404       |New York-Newark-Jersey City, NY-NJ-PA|\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|4          |2018-11-30 13:20:44.796|43     |free |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|618       |San Antonio-New Braunfels, TX        |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|5          |2018-11-16 16:40:43.796|97     |paid |SOXZYWX12A6310ED0C|ARC1IHZ1187FB4E920|633       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|1          |2018-11-21 05:30:19.796|97     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|797       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|17179869184|2018-11-06 20:05:45.796|97     |paid |SOBLFFE12AF72AA5BA|ARJNIUY12298900C91|293       |Lansing-East Lansing, MI             |\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"     |2018|11   |\n",
      "|8589934592 |2018-11-20 00:51:41.796|25     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|594       |Marinette, WI-MI                     |\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"|2018|11   |\n",
      "|8589934594 |2018-11-27 17:08:42.796|36     |paid |SORRNOC12AB017F52B|ARSZ7L31187FB4E610|957       |Janesville-Beloit, WI                |\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"       |2018|11   |\n",
      "|3          |2018-11-05 02:21:55.796|44     |paid |SONRWUU12AF72A4283|ARGE7G11187FB37E05|237       |Waterloo-Cedar Falls, IA             |Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0                              |2018|11   |\n",
      "|8589934593 |2018-11-19 15:36:04.796|49     |paid |SOFSOCN12A8C143F5D|ARXR32B1187FB57099|724       |San Francisco-Oakland-Hayward, CA    |Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0                                              |2018|11   |\n",
      "|2          |2018-11-28 16:54:51.796|14     |free |SOIGHOD12A8C13B5A1|ARY589G1187B9A9F4E|929       |Red Bluff, CA                        |Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0                                       |2018|11   |\n",
      "+-----------+-----------------------+-------+-----+------------------+------------------+----------+-------------------------------------+---------------------------------------------------------------------------------------------------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check data in each table and the parquets files\n",
    "%run -i '04_checkData.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame rows: 6813\n",
      "DataFrame schema: DataFrame[start_time: timestamp, hour: int, day: int, week: int, weekday: string, year: int, month: int]\n",
      "+-----------------------+----+---+----+-------+----+-----+\n",
      "|start_time             |hour|day|week|weekday|year|month|\n",
      "+-----------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-10 17:50:52.796|17  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 18:15:27.796|18  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:08:52.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:10:48.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:14:26.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:30:33.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:35:14.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:39:08.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:43:48.796|19  |10 |45  |7      |2018|11   |\n",
      "|2018-11-10 19:47:29.796|19  |10 |45  |7      |2018|11   |\n",
      "+-----------------------+----+---+----+-------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df9 = spark.read.parquet('output/time_table')\n",
    "print('DataFrame rows: %d' % df9.count())\n",
    "print('DataFrame schema: %s' % df9)\n",
    "df9.select('start_time', 'hour', 'day', 'week', 'weekday', 'year', 'month') \\\n",
    "    .sort('year', 'month') \\\n",
    "    .show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
